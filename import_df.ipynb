{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_exel_path = 'spark_example_files\\\\online_retail.xlsx'\n",
    "file_csv_path = 'spark_example_files\\\\online_retail.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(file_exel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(file_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Spark Example').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = spark.read.csv(file_csv_path, header=True, inferSchema=True)\n",
    "dfs.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|   13047.0|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|   13047.0|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|   13047.0|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|   13047.0|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|   13047.0|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|   13047.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк: 541909\n"
     ]
    }
   ],
   "source": [
    "print(f'Количество строк: {dfs.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных клиентов:  4373\n"
     ]
    }
   ],
   "source": [
    "unique_count = dfs.select('CustomerID').distinct().count()\n",
    "print(\"Количество уникальных клиентов: \", unique_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшее количество покупок в: Row(Country='United Kingdom', count=495478)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Группировка по столбцу и подсчет количества записей\n",
    "grouped_dfs = dfs.groupBy('Country').count()\n",
    "\n",
    "# Сортировка по убыванию количества записей\n",
    "sorted_dfs = grouped_dfs.orderBy(F.desc('count'))\n",
    "\n",
    "# Получение наиболее повторяющейся записи\n",
    "most_frequent_record = sorted_dfs.first()\n",
    "\n",
    "print(\"Наибольшее количество покупок в:\", most_frequent_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|first_date         |last_date          |\n",
      "+-------------------+-------------------+\n",
      "|2010-12-01 08:26:00|2011-12-09 12:50:00|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "\n",
    "result_dfs_date = dfs.agg(min('InvoiceDate').alias('first_date'), max('InvoiceDate').alias('last_date'))\n",
    "result_dfs_date.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, when, count, avg\n",
    "\n",
    "# Предположим, что текущая дата - это последняя дата в дата фрейме\n",
    "current_date = lit('2011-12-09').cast('date')\n",
    "\n",
    "dfs = dfs.withColumn('InvoiceDate', col('InvoiceDate'))\n",
    "\n",
    "# Рассчитываем Recency, Frequency и Monetary\n",
    "recency_df = dfs.groupBy('CustomerID').agg(\n",
    "    (current_date - max('InvoiceDate').cast('date')).alias('Recency')\n",
    ")\n",
    "\n",
    "# recency_df = dfs.groupBy('CustomerID').agg(\n",
    "#     (max('InvoiceDate').cast('timestamp') - current_date).alias('Recency')\n",
    "# )\n",
    "\n",
    "frequency_df = dfs.groupBy('CustomerID').agg(\n",
    "    count('InvoiceNo').alias('Frequency')\n",
    ")\n",
    "\n",
    "monetary_df = dfs.groupBy('CustomerID').agg(\n",
    "    avg(col('UnitPrice') * col('Quantity')).alias('Monetary')\n",
    ")\n",
    "\n",
    "# Объединяем все параметры в один DataFrame\n",
    "rfm_df = recency_df.join(frequency_df, 'CustomerID').join(monetary_df, 'CustomerID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+------------------+\n",
      "|CustomerID|           Recency|Frequency|          Monetary|\n",
      "+----------+------------------+---------+------------------+\n",
      "|   16916.0| INTERVAL '23' DAY|      143|4.0297902097902085|\n",
      "|   17884.0|  INTERVAL '3' DAY|      117| 6.132051282051282|\n",
      "|   13094.0| INTERVAL '21' DAY|       30| 56.96200000000001|\n",
      "|   16596.0| INTERVAL '15' DAY|       12|20.845833333333335|\n",
      "|   17633.0| INTERVAL '31' DAY|       72| 17.25472222222222|\n",
      "|   16858.0|INTERVAL '366' DAY|       13|26.606923076923085|\n",
      "|   13649.0|INTERVAL '256' DAY|       23|15.069565217391306|\n",
      "|   16656.0| INTERVAL '22' DAY|       80|           107.103|\n",
      "|   15160.0|INTERVAL '357' DAY|        4|39.540000000000006|\n",
      "|   18277.0| INTERVAL '58' DAY|        9|10.847777777777777|\n",
      "|   15311.0|  INTERVAL '0' DAY|     2491|23.853608992372532|\n",
      "|   17659.0|  INTERVAL '3' DAY|      161|18.352484472049685|\n",
      "|   12967.0|  INTERVAL '3' DAY|       33| 36.20454545454545|\n",
      "|   17062.0|INTERVAL '313' DAY|       71|7.5277464788732384|\n",
      "|   16353.0|  INTERVAL '3' DAY|       94| 71.01819148936171|\n",
      "|   15898.0|  INTERVAL '1' DAY|       87| 15.91586206896552|\n",
      "|   15750.0|  INTERVAL '2' DAY|      295| 8.309254237288133|\n",
      "|   17392.0|INTERVAL '306' DAY|       62| 7.385645161290323|\n",
      "|   16600.0|  INTERVAL '4' DAY|       62|13.121290322580647|\n",
      "|   12609.0| INTERVAL '78' DAY|       60| 18.78083333333333|\n",
      "+----------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfm_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем на группы (A, B, C) для каждого параметра\n",
    "# Давность (Recency)\n",
    "rfm_df = rfm_df.withColumn('RecencyGroup',\n",
    "                           when(col('Recency').cast('int') <= 30, lit('A'))\n",
    "                           .when((col('Recency').cast('int') > 30) & (col('Recency').cast('int') <= 60), lit('B'))\n",
    "                           .otherwise(lit('C')))\n",
    "\n",
    "# Частота (Frequency)\n",
    "rfm_df = rfm_df.withColumn('FrequencyGroup',\n",
    "                           when(col('Frequency') >= 100, lit('A'))\n",
    "                           .when((col('Frequency') < 100) & (col('Frequency') >= 50), lit('B'))\n",
    "                           .otherwise(lit('C')))\n",
    "\n",
    "# Денежная ценность (Monetary)\n",
    "rfm_df = rfm_df.withColumn('MonetaryGroup',\n",
    "                           when(col('Monetary') >= 100, lit('A'))\n",
    "                           .when((col('Monetary') < 100) & (col('Monetary') >= 50), lit('B'))\n",
    "                           .otherwise(lit('C')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat\n",
    "# Итоговый столбец с суммой значений групп по каждому параметру\n",
    "rfm_df = rfm_df.withColumn('RFMSum',\n",
    "                           concat(col('RecencyGroup'), col('FrequencyGroup'), col('MonetaryGroup')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = rfm_df.filter(col('RFMSum') == 'AAA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем результат в CSV-файл\n",
    "result_df.toPandas().to_csv('online_retail_rfm.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
